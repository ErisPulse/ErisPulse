#!/usr/bin/env python3
"""
è‰¾è‰ä¸çš„ç±»å‹ç‚¼é‡‘å·¥æˆ¿ - ç±»å‹å­˜æ ¹ç”Ÿæˆå™¨

ä»Pythonæºä»£ç è‡ªåŠ¨ç”Ÿæˆ.pyiç±»å‹å­˜æ ¹æ–‡ä»¶ï¼Œæ”¯æŒï¼š
- ç±»ã€å‡½æ•°ã€æ–¹æ³•çš„ç±»å‹æ³¨è§£æå–
- å‚æ•°å’Œè¿”å›å€¼ç±»å‹æ ‡æ³¨
- ç»§æ‰¿å…³ç³»
- æ–‡æ¡£å­—ç¬¦ä¸²è½¬æ¢
- å¢é‡æ›´æ–°æœºåˆ¶
"""

import ast
import argparse
import hashlib
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Set


class TypeStubGenerator:
    """ç±»å‹å­˜æ ¹ç”Ÿæˆå™¨"""
    
    # éœ€è¦å¿½ç•¥çš„ç‰¹æ®Šæ ‡ç­¾
    IGNORE_TAGS = {
        "internal-use",
        "ignore"
    }
    
    def __init__(self, src_dir: str, output_dir: str, force: bool = False, clean: bool = False, clean_only: bool = False):
        self.src_dir = Path(src_dir).resolve()
        self.output_dir = Path(output_dir).resolve()
        self.force = force
        self.clean = clean
        self.clean_only = clean_only
        self.generated_files: Set[Path] = set()
        self.skipped_files: Set[Path] = set()
        self.cleaned_files: Set[Path] = set()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¼“å­˜ç›®å½•ï¼Œç”¨äºå­˜å‚¨æ–‡ä»¶å“ˆå¸Œ
        self.cache_dir = Path(".github/.cache/type-stubs")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # å¦‚æœåªéœ€è¦æ¸…ç†
        if clean_only:
            self._clean_stubs()
            return
        
        # å¦‚æœéœ€è¦æ¸…ç†ï¼Œå…ˆæ¸…ç†æ‰€æœ‰ .pyi æ–‡ä»¶
        if clean:
            self._clean_stubs()
    
    def _clean_stubs(self):
        """æ¸…ç†æ‰€æœ‰ .pyi æ–‡ä»¶"""
        print("ğŸ§¹ è‰¾è‰ä¸æ­£åœ¨æ¸…ç†æ—§çš„ç±»å‹å­˜æ ¹æ–‡ä»¶~")
        
        # æŸ¥æ‰¾æ‰€æœ‰ .pyi æ–‡ä»¶
        pyi_files = list(self.output_dir.rglob("*.pyi"))
        
        for pyi_file in pyi_files:
            try:
                pyi_file.unlink()
                self.cleaned_files.add(pyi_file)
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤ {pyi_file} æ—¶å‡ºé”™: {e}")
        
        # æ¸…ç†ç¼“å­˜
        cache_files = list(self.cache_dir.rglob("*.hash"))
        for cache_file in cache_files:
            try:
                cache_file.unlink()
            except Exception as e:
                print(f"âš ï¸ åˆ é™¤ç¼“å­˜ {cache_file} æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… å·²æ¸…ç† {len(self.cleaned_files)} ä¸ª .pyi æ–‡ä»¶")
    
    def generate(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰€æœ‰ç±»å‹å­˜æ ¹æ–‡ä»¶"""
        print("ğŸ”® è‰¾è‰ä¸å¼€å§‹æ–½å±•ç±»å‹å­˜æ ¹ç”Ÿæˆé­”æ³•~")
        
        # éå†æ‰€æœ‰Pythonæ–‡ä»¶
        python_files = list(self.src_dir.rglob("*.py"))
        total = len(python_files)
        processed = 0
        
        for py_file in python_files:
            # è·³è¿‡__pycache__å’Œæµ‹è¯•æ–‡ä»¶
            if "__pycache__" in str(py_file) or "test" in py_file.name:
                continue
            
            try:
                self._generate_stub(py_file)
                processed += 1
            except Exception as e:
                print(f"âš ï¸ å¤„ç† {py_file} æ—¶å‡ºé”™: {e}")
        
        return {
            "total": total,
            "processed": processed,
            "generated": len(self.generated_files),
            "skipped": len(self.skipped_files),
            "cleaned": len(self.cleaned_files)
        }
    
    def _generate_stub(self, py_file: Path):
        """ä¸ºå•ä¸ªPythonæ–‡ä»¶ç”Ÿæˆç±»å‹å­˜æ ¹"""
        # è®¡ç®—ç›¸å¯¹è·¯å¾„å’Œè¾“å‡ºè·¯å¾„
        rel_path = py_file.relative_to(self.src_dir)
        stub_path = self.output_dir / rel_path.with_suffix(".pyi")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        stub_path.parent.mkdir(parents=True, exist_ok=True)
        
        # è®¡ç®—æºæ–‡ä»¶å“ˆå¸Œ
        content_hash = self._calculate_hash(py_file)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆå¦‚æœ force ä¸º Trueï¼Œåˆ™è·³è¿‡ç¼“å­˜æ£€æŸ¥ï¼‰
        if not self.force:
            cache_file = self.cache_dir / f"{rel_path.with_suffix('.hash')}"
            cache_file.parent.mkdir(parents=True, exist_ok=True)
            
            if cache_file.exists():
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached_hash = f.read().strip()
                    if cached_hash == content_hash and stub_path.exists():
                        self.skipped_files.add(stub_path)
                        return
        
        # è¯»å–å¹¶è§£ææºæ–‡ä»¶
        with open(py_file, 'r', encoding='utf-8') as f:
            source = f.read()
        
        try:
            tree = ast.parse(source)
        except SyntaxError as e:
            print(f"âš ï¸ æ— æ³•è§£æ {py_file}: {e}")
            return
        
        # ç”Ÿæˆç±»å‹å­˜æ ¹å†…å®¹
        stub_content = self._generate_stub_content(tree, py_file)
        
        # å†™å…¥ç±»å‹å­˜æ ¹æ–‡ä»¶
        with open(stub_path, 'w', encoding='utf-8') as f:
            f.write(stub_content)
        
        # æ›´æ–°ç¼“å­˜
        cache_file = self.cache_dir / f"{rel_path.with_suffix('.hash')}"
        cache_file.parent.mkdir(parents=True, exist_ok=True)
        with open(cache_file, 'w', encoding='utf-8') as f:
            f.write(content_hash)
        
        self.generated_files.add(stub_path)
    
    def _generate_stub_content(self, tree: ast.AST, source_file: Path) -> str:
        """ç”Ÿæˆç±»å‹å­˜æ ¹æ–‡ä»¶å†…å®¹"""
        lines = []
        
        # æ·»åŠ æ–‡ä»¶å¤´éƒ¨æ³¨é‡Š
        lines.append('# type: ignore')
        lines.append('#')
        lines.append(f'# Auto-generated type stub for {source_file.name}')
        lines.append(f'# DO NOT EDIT MANUALLY - Generated by generate-type-stubs.py')
        lines.append('#')
        lines.append('')
        
        # æå–æ¨¡å—æ–‡æ¡£å­—ç¬¦ä¸²
        module_docstring = ast.get_docstring(tree)
        if module_docstring:
            lines.append('"""')
            lines.append(module_docstring)
            lines.append('"""')
            lines.append('')
        
        # å¤„ç†å¯¼å…¥è¯­å¥
        imports = self._extract_imports(tree)
        if imports:
            lines.extend(imports)
            lines.append('')
        
        # å¤„ç†ç±»å’Œå‡½æ•°å®šä¹‰
        for node in tree.body:
            if isinstance(node, ast.ClassDef):
                if not self._should_ignore(node):
                    class_def = self._generate_class_def(node)
                    lines.append(class_def)
                    lines.append('')
            elif isinstance(node, ast.FunctionDef) or isinstance(node, ast.AsyncFunctionDef):
                if not self._should_ignore(node):
                    func_def = self._generate_function_def(node)
                    lines.append(func_def)
                    lines.append('')
            elif isinstance(node, ast.AnnAssign):
                # å¤„ç†ç±»å‹å˜é‡èµ‹å€¼
                var_def = self._generate_var_def(node)
                if var_def:
                    lines.append(var_def)
                    lines.append('')
        
        return '\n'.join(lines)
    
    def _extract_imports(self, tree: ast.AST) -> List[str]:
        """æå–æ‰€æœ‰å¯¼å…¥è¯­å¥ï¼ˆä»…é™é¡¶å±‚å¯¼å…¥ï¼‰"""
        imports = []
        seen_imports = set()
        
        # åªå¤„ç†é¡¶å±‚å¯¼å…¥ï¼Œè·³è¿‡å‡½æ•°/ç±»å†…éƒ¨çš„å¯¼å…¥
        for node in tree.body:
            if isinstance(node, ast.ImportFrom):
                # ç›¸å¯¹å¯¼å…¥
                module = node.module or ''
                names = []
                for alias in node.names:
                    if alias.asname:
                        names.append(f"{alias.name} as {alias.asname}")
                    else:
                        names.append(alias.name)
                if names:
                    level = '.' * node.level
                    import_stmt = f"from {level}{module} import {', '.join(names)}"
                    if import_stmt not in seen_imports:
                        imports.append(import_stmt)
                        seen_imports.add(import_stmt)
            elif isinstance(node, ast.Import):
                names = []
                for alias in node.names:
                    if alias.asname:
                        names.append(f"{alias.name} as {alias.asname}")
                    else:
                        names.append(alias.name)
                import_stmt = f"import {', '.join(names)}"
                if import_stmt not in seen_imports:
                    imports.append(import_stmt)
                    seen_imports.add(import_stmt)
        
        return imports
    
    def _generate_class_def(self, node: ast.ClassDef) -> str:
        """ç”Ÿæˆç±»å®šä¹‰"""
        # ç±»åå’ŒåŸºç±»
        bases = []
        for base in node.bases:
            if isinstance(base, ast.Name):
                bases.append(base.id)
            elif isinstance(base, ast.Attribute):
                bases.append(self._get_attribute_name(base))
        
        bases_str = f"({', '.join(bases)})" if bases else ""
        
        # æå–ç±»æ–‡æ¡£å­—ç¬¦ä¸²
        docstring = ast.get_docstring(node)
        
        # æ”¶é›†æ‰€æœ‰æˆå‘˜
        members = []
        for item in node.body:
            if isinstance(item, ast.FunctionDef) or isinstance(item, ast.AsyncFunctionDef):
                if not self._should_ignore(item):
                    members.append(self._generate_method_def(item))
            elif isinstance(item, ast.AnnAssign):
                if item.annotation:
                    var_name = self._get_var_name(item.target)
                    annotation = self._get_annotation(item.annotation)
                    members.append(f"    {var_name}: {annotation}")
        
        # ç”Ÿæˆç±»å®šä¹‰
        lines = []
        lines.append(f"class {node.name}{bases_str}:")
        
        if docstring:
            lines.append('    """')
            for line in docstring.split('\n'):
                lines.append(f'    {line}')
            lines.append('    """')
        
        if members:
            lines.extend(members)
        else:
            lines.append("    ...")
        
        return '\n'.join(lines)
    
    def _generate_method_def(self, node: ast.FunctionDef) -> str:
        """ç”Ÿæˆæ–¹æ³•å®šä¹‰"""
        # æ–¹æ³•å
        is_async = isinstance(node, ast.AsyncFunctionDef)
        async_prefix = "async " if is_async else ""
        
        # æå–æ–‡æ¡£å­—ç¬¦ä¸²
        docstring = ast.get_docstring(node)
        
        # å‚æ•°
        params = self._generate_params(node)
        
        # è¿”å›ç±»å‹
        return_type = self._get_annotation(node.returns) if node.returns else "..."
        
        # ç”Ÿæˆæ–¹æ³•å®šä¹‰
        decorator = "    "
        decorator_line = decorator + f"{async_prefix}def {node.name}{params} -> {return_type}:"
        
        if docstring:
            lines = [decorator_line]
            lines.append('        """')
            for line in docstring.split('\n'):
                lines.append(f'        {line}')
            lines.append('        """')
            lines.append("        ...")
            return '\n'.join(lines)
        else:
            return f"{decorator_line}\n        ..."
    
    def _generate_function_def(self, node: ast.FunctionDef) -> str:
        """ç”Ÿæˆå‡½æ•°å®šä¹‰"""
        is_async = isinstance(node, ast.AsyncFunctionDef)
        async_prefix = "async " if is_async else ""
        
        # æå–æ–‡æ¡£å­—ç¬¦ä¸²
        docstring = ast.get_docstring(node)
        
        # å‚æ•°
        params = self._generate_params(node)
        
        # è¿”å›ç±»å‹
        return_type = self._get_annotation(node.returns) if node.returns else "..."
        
        # ç”Ÿæˆå‡½æ•°å®šä¹‰
        line = f"{async_prefix}def {node.name}{params} -> {return_type}:"
        
        if docstring:
            lines = [line]
            lines.append('    """')
            for line in docstring.split('\n'):
                lines.append(f'    {line}')
            lines.append('    """')
            lines.append("    ...")
            return '\n'.join(lines)
        else:
            return f"{line}\n    ..."
    
    def _generate_params(self, node: ast.FunctionDef) -> str:
        """ç”Ÿæˆå‚æ•°åˆ—è¡¨"""
        params = []
        
        # ç‰¹æ®Šå¤„ç† __init__ æ–¹æ³•
        is_init = node.name == '__init__'
        
        # å¤„ç†ä½ç½®å‚æ•°å’Œå…³é”®å­—å‚æ•°
        for arg in node.args.posonlyargs:
            param = self._generate_param(arg, node)
            params.append(param)
        
        if node.args.posonlyargs:
            params.append("/")
        
        # å¤„ç†æ™®é€šå‚æ•°
        if node.args.args:
            # æ£€æŸ¥ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å¦æ˜¯ self æˆ– cls
            first_arg = node.args.args[0]
            if first_arg.arg in ('self', 'cls'):
                # æ·»åŠ  self æˆ– cls å‚æ•°
                param_name = first_arg.arg
                annotation = self._get_annotation(first_arg.annotation) if first_arg.annotation else ("None" if is_init else "object")
                params.append(f"{param_name}: {annotation}")
                # æ·»åŠ å‰©ä½™å‚æ•°
                for arg in node.args.args[1:]:
                    param = self._generate_param(arg, node)
                    params.append(param)
            else:
                # æ²¡æœ‰ç‰¹æ®Šå‚æ•°ï¼Œå…¨éƒ¨æ·»åŠ 
                for arg in node.args.args:
                    param = self._generate_param(arg, node)
                    params.append(param)
        
        # å¤„ç† *args
        if node.args.vararg:
            param = self._generate_param(node.args.vararg, node, is_vararg=True)
            params.append(param)
        
        # å¤„ç† **kwargs
        if node.args.kwarg:
            param = self._generate_param(node.args.kwarg, node, is_kwarg=True)
            params.append(param)
        
        return f"({', '.join(params)})"
    
    def _generate_param(self, arg: ast.arg, node: ast.FunctionDef, 
                        is_vararg: bool = False, is_kwarg: bool = False) -> str:
        """ç”Ÿæˆå•ä¸ªå‚æ•°"""
        param_name = arg.arg
        
        # æ·»åŠ æ˜Ÿå·
        if is_vararg:
            param_name = f"*{param_name}"
        elif is_kwarg:
            param_name = f"**{param_name}"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é»˜è®¤å€¼
        has_default = False
        defaults_offset = len(node.args.args) - len(node.args.defaults)
        if arg in node.args.args:
            idx = node.args.args.index(arg)
            has_default = idx >= defaults_offset
        elif arg == node.args.vararg or arg == node.args.kwarg:
            has_default = False
        
        # è·å–ç±»å‹æ³¨è§£
        annotation = self._get_annotation(arg.annotation) if arg.annotation else "..."
        
        # ç”Ÿæˆå‚æ•°å­—ç¬¦ä¸²
        if has_default:
            return f"{param_name}: {annotation} = ..."
        else:
            return f"{param_name}: {annotation}"
    
    def _generate_var_def(self, node: ast.AnnAssign) -> Optional[str]:
        """ç”Ÿæˆå˜é‡å®šä¹‰"""
        if not node.annotation:
            return None
        
        var_name = self._get_var_name(node.target)
        annotation = self._get_annotation(node.annotation)
        
        return f"{var_name}: {annotation}"
    
    def _get_annotation(self, annotation: ast.AST) -> str:
        """è·å–ç±»å‹æ³¨è§£å­—ç¬¦ä¸²"""
        if annotation is None:
            return "..."
        
        if isinstance(annotation, ast.Name):
            return annotation.id
        elif isinstance(annotation, ast.Attribute):
            return self._get_attribute_name(annotation)
        elif isinstance(annotation, ast.Subscript):
            value = self._get_annotation(annotation.value)
            slice_val = self._get_annotation(annotation.slice)
            return f"{value}[{slice_val}]"
        elif isinstance(annotation, ast.Tuple):
            elts = [self._get_annotation(elt) for elt in annotation.elts]
            return f"({', '.join(elts)})"
        elif isinstance(annotation, ast.BinOp):
            left = self._get_annotation(annotation.left)
            right = self._get_annotation(annotation.right)
            op = " | " if isinstance(annotation.op, ast.BitOr) else " & "
            return f"{left}{op}{right}"
        elif isinstance(annotation, ast.Constant):
            return str(annotation.value)
        elif isinstance(annotation, ast.List):
            elts = [self._get_annotation(elt) for elt in annotation.elts]
            return f"[{', '.join(elts)}]"
        elif isinstance(annotation, ast.Dict):
            keys = [self._get_annotation(k) for k in annotation.keys]
            values = [self._get_annotation(v) for v in annotation.values]
            kv_pairs = [f"{k}: {v}" for k, v in zip(keys, values)]
            return f"{{{', '.join(kv_pairs)}}}"
        else:
            return "..."
    
    def _get_attribute_name(self, node: ast.Attribute) -> str:
        """è·å–å±æ€§è®¿é—®çš„å®Œæ•´åç§°"""
        if isinstance(node.value, ast.Name):
            return f"{node.value.id}.{node.attr}"
        elif isinstance(node.value, ast.Attribute):
            return f"{self._get_attribute_name(node.value)}.{node.attr}"
        else:
            return node.attr
    
    def _get_var_name(self, target: ast.AST) -> str:
        """è·å–å˜é‡å"""
        if isinstance(target, ast.Name):
            return target.id
        elif isinstance(target, ast.Attribute):
            return self._get_attribute_name(target)
        else:
            return "..."
    
    def _should_ignore(self, node: ast.AST) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥æ­¤èŠ‚ç‚¹"""
        docstring = ast.get_docstring(node)
        if not docstring:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿½ç•¥æ ‡ç­¾
        for tag in self.IGNORE_TAGS:
            if f"{{!--< {tag} >!--}}" in docstring:
                return True
        
        return False
    
    def _calculate_hash(self, file_path: Path) -> str:
        """è®¡ç®—æ–‡ä»¶å†…å®¹çš„å“ˆå¸Œå€¼"""
        with open(file_path, 'rb') as f:
            return hashlib.md5(f.read()).hexdigest()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ğŸ”® è‰¾è‰ä¸çš„ç±»å‹ç‚¼é‡‘å·¥æˆ¿ - è‡ªåŠ¨ç”Ÿæˆç±»å‹å­˜æ ¹æ–‡ä»¶"
    )
    parser.add_argument(
        "--src",
        type=str,
        default="src",
        help="æºä»£ç ç›®å½• (é»˜è®¤: src)"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="src",
        help="è¾“å‡ºç›®å½•ï¼Œä¸æºç›®å½•ç›¸åŒä»¥ç”Ÿæˆ.pyiæ–‡ä»¶ (é»˜è®¤: src)"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ‰€æœ‰ç±»å‹å­˜æ ¹æ–‡ä»¶ï¼Œå¿½ç•¥ç¼“å­˜"
    )
    parser.add_argument(
        "--clean",
        action="store_true",
        help="åœ¨ç”Ÿæˆå‰æ¸…ç†æ‰€æœ‰ç°æœ‰çš„ .pyi æ–‡ä»¶"
    )
    parser.add_argument(
        "--clean-only",
        action="store_true",
        help="åªæ¸…ç†æ‰€æœ‰ç°æœ‰çš„ .pyi æ–‡ä»¶ï¼Œä¸ç”Ÿæˆæ–°çš„æ–‡ä»¶"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = TypeStubGenerator(args.src, args.output, force=args.force, clean=args.clean, clean_only=args.clean_only)
    
    # å¦‚æœåªæ˜¯æ¸…ç†ï¼Œç›´æ¥è¿”å›
    if args.clean_only:
        print(f"\nâœ¨ æ¸…ç†å®Œæˆ! å·²åˆ é™¤ {len(generator.cleaned_files)} ä¸ª .pyi æ–‡ä»¶")
        return 0
    
    # ç”Ÿæˆç±»å‹å­˜æ ¹
    stats = generator.generate()
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š è‰¾è‰ä¸çš„ç»Ÿè®¡æŠ¥å‘Š:")
    print(f"  æ€»æ–‡ä»¶æ•°: {stats['total']}")
    print(f"  å¤„ç†æ–‡ä»¶: {stats['processed']}")
    if stats.get('cleaned', 0) > 0:
        print(f"  æ¸…ç†æ–‡ä»¶: {stats['cleaned']}")
    print(f"  ç”Ÿæˆæ–‡ä»¶: {stats['generated']}")
    print(f"  è·³è¿‡æ–‡ä»¶: {stats['skipped']}")
    print(f"\nâœ¨ ç±»å‹å­˜æ ¹ç”Ÿæˆå®Œæˆ!")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
